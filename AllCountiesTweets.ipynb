{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the main file please don't tamper with it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "import time\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter API credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = \"4xihrxvf1Sbuaufe7RWNNGBQ4c\"\n",
    "consumer_secret = \"wyzB7mZvxzlFOUFakETiV5USLStSX0zEaQP4qinU4QUnOjWeZxi\"\n",
    "access_key = \"2x306144275-Oc7NnFdC7H9v5BjAysBz7si4OWZ9N7xmIc6XbLl\"\n",
    "access_secret = \"UFLgsZzTYptlDTQUjjLfhG4tZzVvPkgYDVuMPitYOAVFxA\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authorize twitter, initialize tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a list of all counties for which we need tweets. We will iterate through this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties = [\"BondCountyHD\", \"boonecohealth\", \"CU_PublicHealth\", \"ChiPublicHealth\", \"CookCtyHealth\", \"DeKalbCoHD\", \"DuPageHD\", \n",
    "            \"fwbicohealth\", \"KaneCoHealth\", \"kankakeehealth\", \"kendallhealth\", \"kchd92\", \"LakeCoHealth\", \"LaSalleCoHealth\", \"LCHD_IL\", \n",
    "            \"LCHD_Illinois\", \"Maconcountyhd\", \"MacoupinHealth\", \"McHenryCoHealth\", \"McLeanHealth\", \"vopnews\", \n",
    "            \"peoriaprepare\", \"polkcohealth\", \"RICO_HealthDept\", \"HenryStarkHD\", \"stclairhealth\", \"ERCSCHD\", \n",
    "            \"tazewellhealth\", \"Whiteside_CHC\", \"WillCoHealth\", \"WinnCoHealth\", \"WoodfordHealth\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to retrieve all hashtags in a tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHashtags(tweet):\n",
    "    #hashtags=[None]*len(tweet[\"entities\"][\"hashtags\"])\n",
    "    hashtags=[]\n",
    "    if len(tweet[\"entities\"][\"hashtags\"]) > 0:\n",
    "        for i in range(len(tweet[\"entities\"][\"hashtags\"])-1):\n",
    "            hashtags.append(tweet[\"entities\"][\"hashtags\"][i]['text'])\n",
    "        #print(hashtags)\n",
    "        hashtags=list(set(hashtags))\n",
    "        hashtags=' '.join(hashtags)\n",
    "    return hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to know if the tweet has image/video/etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMedia(tweet):\n",
    "    try:\n",
    "        value = tweet['extended_entities']['media'][0]['type']\n",
    "        return value\n",
    "    except KeyError:\n",
    "        return \"NA\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to get date time in a proper format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDate(tweet):\n",
    "    return time.strftime('%Y-%m-%d %H:%M:%S', time.strptime(tweet['created_at'],'%a %b %d %H:%M:%S +0000 %Y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to get tweet source from HTML format (Get value of anchor tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTweetSource(tweet):\n",
    "    #Beautiful Soup is used here\n",
    "    soup=BS(tweet)\n",
    "    return soup.find('a', {'rel':'nofollow'}).text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to know if it is a retweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTweetType(tweet):\n",
    "    if re.search('^RT\\s@*', tweet):\n",
    "        return \"Retweet\"\n",
    "    else:\n",
    "        return \"Tweet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to get URL of a tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTweetURL(tweet):\n",
    "    url = \"twitter.com/\" + tweet['user']['screen_name'] + \"/status/\" + tweet['id_str']\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating through the list and generating a csv for each county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...400 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /home/ec2-user/anaconda3/envs/python3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...1000 tweets downloaded so far\n",
      "...1200 tweets downloaded so far\n",
      "...1224 tweets downloaded so far\n",
      "...1224 tweets downloaded so far\n",
      "BondCountyHD  County is done----------------------------------------------------------\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...603 tweets downloaded so far\n",
      "...603 tweets downloaded so far\n",
      "boonecohealth  County is done----------------------------------------------------------\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...799 tweets downloaded so far\n",
      "...999 tweets downloaded so far\n",
      "...1199 tweets downloaded so far\n",
      "...1396 tweets downloaded so far\n",
      "...1596 tweets downloaded so far\n",
      "...1796 tweets downloaded so far\n",
      "...1996 tweets downloaded so far\n",
      "...2196 tweets downloaded so far\n",
      "...2264 tweets downloaded so far\n",
      "...2264 tweets downloaded so far\n",
      "CU_PublicHealth  County is done----------------------------------------------------------\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...1000 tweets downloaded so far\n",
      "...1200 tweets downloaded so far\n",
      "...1399 tweets downloaded so far\n",
      "...1599 tweets downloaded so far\n",
      "...1797 tweets downloaded so far\n",
      "...1997 tweets downloaded so far\n",
      "...2196 tweets downloaded so far\n",
      "...2396 tweets downloaded so far\n",
      "...2596 tweets downloaded so far\n",
      "...2795 tweets downloaded so far\n",
      "...2994 tweets downloaded so far\n",
      "...3194 tweets downloaded so far\n",
      "...3205 tweets downloaded so far\n",
      "...3205 tweets downloaded so far\n",
      "ChiPublicHealth  County is done----------------------------------------------------------\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...999 tweets downloaded so far\n",
      "...1199 tweets downloaded so far\n",
      "...1399 tweets downloaded so far\n",
      "...1599 tweets downloaded so far\n",
      "...1799 tweets downloaded so far\n",
      "...1999 tweets downloaded so far\n",
      "...2102 tweets downloaded so far\n",
      "...2102 tweets downloaded so far\n",
      "CookCtyHealth  County is done----------------------------------------------------------\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...935 tweets downloaded so far\n",
      "...935 tweets downloaded so far\n",
      "DeKalbCoHD  County is done----------------------------------------------------------\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...1000 tweets downloaded so far\n",
      "...1200 tweets downloaded so far\n",
      "...1400 tweets downloaded so far\n",
      "...1598 tweets downloaded so far\n",
      "...1798 tweets downloaded so far\n",
      "...1853 tweets downloaded so far\n",
      "...1853 tweets downloaded so far\n",
      "DuPageHD  County is done----------------------------------------------------------\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...1000 tweets downloaded so far\n",
      "...1172 tweets downloaded so far\n",
      "...1172 tweets downloaded so far\n",
      "fwbicohealth  County is done----------------------------------------------------------\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...1000 tweets downloaded so far\n",
      "...1200 tweets downloaded so far\n",
      "...1400 tweets downloaded so far\n",
      "...1600 tweets downloaded so far\n",
      "...1800 tweets downloaded so far\n",
      "...2000 tweets downloaded so far\n",
      "...2200 tweets downloaded so far\n",
      "...2400 tweets downloaded so far\n",
      "...2600 tweets downloaded so far\n",
      "...2800 tweets downloaded so far\n",
      "...3000 tweets downloaded so far\n",
      "...3200 tweets downloaded so far\n",
      "...3217 tweets downloaded so far\n",
      "...3217 tweets downloaded so far\n",
      "KaneCoHealth  County is done----------------------------------------------------------\n",
      "...396 tweets downloaded so far\n",
      "...396 tweets downloaded so far\n",
      "kankakeehealth  County is done----------------------------------------------------------\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...813 tweets downloaded so far\n",
      "...813 tweets downloaded so far\n",
      "kendallhealth  County is done----------------------------------------------------------\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...1000 tweets downloaded so far\n",
      "...1200 tweets downloaded so far\n",
      "...1400 tweets downloaded so far\n",
      "...1600 tweets downloaded so far\n",
      "...1800 tweets downloaded so far\n",
      "...1812 tweets downloaded so far\n",
      "...1812 tweets downloaded so far\n",
      "kchd92  County is done----------------------------------------------------------\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...1000 tweets downloaded so far\n",
      "...1200 tweets downloaded so far\n",
      "...1400 tweets downloaded so far\n",
      "...1600 tweets downloaded so far\n",
      "...1800 tweets downloaded so far\n",
      "...2000 tweets downloaded so far\n",
      "...2200 tweets downloaded so far\n",
      "...2400 tweets downloaded so far\n",
      "...2600 tweets downloaded so far\n",
      "...2800 tweets downloaded so far\n",
      "...3000 tweets downloaded so far\n",
      "...3196 tweets downloaded so far\n",
      "...3234 tweets downloaded so far\n",
      "...3234 tweets downloaded so far\n",
      "LakeCoHealth  County is done----------------------------------------------------------\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...977 tweets downloaded so far\n",
      "...977 tweets downloaded so far\n",
      "LaSalleCoHealth  County is done----------------------------------------------------------\n",
      "...226 tweets downloaded so far\n",
      "...226 tweets downloaded so far\n",
      "LCHD_IL  County is done----------------------------------------------------------\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...1000 tweets downloaded so far\n",
      "...1200 tweets downloaded so far\n",
      "...1400 tweets downloaded so far\n",
      "...1600 tweets downloaded so far\n",
      "...1800 tweets downloaded so far\n",
      "...1860 tweets downloaded so far\n",
      "...1860 tweets downloaded so far\n",
      "LCHD_Illinois  County is done----------------------------------------------------------\n",
      "...97 tweets downloaded so far\n",
      "Maconcountyhd  County is done----------------------------------------------------------\n",
      "...201 tweets downloaded so far\n",
      "...201 tweets downloaded so far\n",
      "MacoupinHealth  County is done----------------------------------------------------------\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...1000 tweets downloaded so far\n",
      "...1198 tweets downloaded so far\n",
      "...1398 tweets downloaded so far\n",
      "...1598 tweets downloaded so far\n",
      "...1798 tweets downloaded so far\n",
      "...1998 tweets downloaded so far\n",
      "...2198 tweets downloaded so far\n",
      "...2398 tweets downloaded so far\n",
      "...2478 tweets downloaded so far\n",
      "...2478 tweets downloaded so far\n",
      "McHenryCoHealth  County is done----------------------------------------------------------\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...1000 tweets downloaded so far\n",
      "...1200 tweets downloaded so far\n",
      "...1400 tweets downloaded so far\n",
      "...1600 tweets downloaded so far\n",
      "...1800 tweets downloaded so far\n",
      "...2000 tweets downloaded so far\n",
      "...2200 tweets downloaded so far\n",
      "...2400 tweets downloaded so far\n",
      "...2441 tweets downloaded so far\n",
      "...2441 tweets downloaded so far\n",
      "McLeanHealth  County is done----------------------------------------------------------\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...1000 tweets downloaded so far\n",
      "...1200 tweets downloaded so far\n",
      "...1400 tweets downloaded so far\n",
      "...1600 tweets downloaded so far\n",
      "...1800 tweets downloaded so far\n",
      "...2000 tweets downloaded so far\n",
      "...2200 tweets downloaded so far\n",
      "...2400 tweets downloaded so far\n",
      "...2600 tweets downloaded so far\n",
      "...2800 tweets downloaded so far\n",
      "...3000 tweets downloaded so far\n",
      "...3200 tweets downloaded so far\n",
      "...3241 tweets downloaded so far\n",
      "...3241 tweets downloaded so far\n",
      "vopnews  County is done----------------------------------------------------------\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...1000 tweets downloaded so far\n",
      "...1200 tweets downloaded so far\n",
      "...1400 tweets downloaded so far\n",
      "...1600 tweets downloaded so far\n",
      "...1800 tweets downloaded so far\n",
      "...2000 tweets downloaded so far\n",
      "...2200 tweets downloaded so far\n",
      "...2400 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...2432 tweets downloaded so far\n",
      "...2432 tweets downloaded so far\n",
      "peoriaprepare  County is done----------------------------------------------------------\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...1000 tweets downloaded so far\n",
      "...1200 tweets downloaded so far\n",
      "...1400 tweets downloaded so far\n",
      "...1600 tweets downloaded so far\n",
      "...1800 tweets downloaded so far\n",
      "...2000 tweets downloaded so far\n",
      "...2200 tweets downloaded so far\n",
      "...2399 tweets downloaded so far\n",
      "...2599 tweets downloaded so far\n",
      "...2799 tweets downloaded so far\n",
      "...2999 tweets downloaded so far\n",
      "...3199 tweets downloaded so far\n",
      "...3215 tweets downloaded so far\n",
      "...3215 tweets downloaded so far\n",
      "polkcohealth  County is done----------------------------------------------------------\n",
      "...74 tweets downloaded so far\n",
      "RICO_HealthDept  County is done----------------------------------------------------------\n",
      "...353 tweets downloaded so far\n",
      "...353 tweets downloaded so far\n",
      "HenryStarkHD  County is done----------------------------------------------------------\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...1000 tweets downloaded so far\n",
      "...1200 tweets downloaded so far\n",
      "...1400 tweets downloaded so far\n",
      "...1600 tweets downloaded so far\n",
      "...1799 tweets downloaded so far\n",
      "...1998 tweets downloaded so far\n",
      "...2197 tweets downloaded so far\n",
      "...2394 tweets downloaded so far\n",
      "...2594 tweets downloaded so far\n",
      "...2729 tweets downloaded so far\n",
      "...2729 tweets downloaded so far\n",
      "stclairhealth  County is done----------------------------------------------------------\n",
      "...128 tweets downloaded so far\n",
      "ERCSCHD  County is done----------------------------------------------------------\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...1000 tweets downloaded so far\n",
      "...1199 tweets downloaded so far\n",
      "...1399 tweets downloaded so far\n",
      "...1599 tweets downloaded so far\n",
      "...1799 tweets downloaded so far\n",
      "...1999 tweets downloaded so far\n",
      "...2052 tweets downloaded so far\n",
      "...2052 tweets downloaded so far\n",
      "tazewellhealth  County is done----------------------------------------------------------\n",
      "...400 tweets downloaded so far\n",
      "...599 tweets downloaded so far\n",
      "...798 tweets downloaded so far\n",
      "...997 tweets downloaded so far\n",
      "...1197 tweets downloaded so far\n",
      "...1397 tweets downloaded so far\n",
      "...1597 tweets downloaded so far\n",
      "...1797 tweets downloaded so far\n",
      "...1997 tweets downloaded so far\n",
      "...2197 tweets downloaded so far\n",
      "...2397 tweets downloaded so far\n",
      "...2597 tweets downloaded so far\n",
      "...2655 tweets downloaded so far\n",
      "...2655 tweets downloaded so far\n",
      "Whiteside_CHC  County is done----------------------------------------------------------\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...1000 tweets downloaded so far\n",
      "...1200 tweets downloaded so far\n",
      "...1400 tweets downloaded so far\n",
      "...1600 tweets downloaded so far\n",
      "...1800 tweets downloaded so far\n",
      "...2000 tweets downloaded so far\n",
      "...2200 tweets downloaded so far\n",
      "...2399 tweets downloaded so far\n",
      "...2597 tweets downloaded so far\n",
      "...2797 tweets downloaded so far\n",
      "...2996 tweets downloaded so far\n",
      "...3196 tweets downloaded so far\n",
      "...3236 tweets downloaded so far\n",
      "...3236 tweets downloaded so far\n",
      "WillCoHealth  County is done----------------------------------------------------------\n",
      "...400 tweets downloaded so far\n",
      "...600 tweets downloaded so far\n",
      "...800 tweets downloaded so far\n",
      "...1000 tweets downloaded so far\n",
      "...1200 tweets downloaded so far\n",
      "...1400 tweets downloaded so far\n",
      "...1600 tweets downloaded so far\n",
      "...1800 tweets downloaded so far\n",
      "...1809 tweets downloaded so far\n",
      "...1809 tweets downloaded so far\n",
      "WinnCoHealth  County is done----------------------------------------------------------\n",
      "...318 tweets downloaded so far\n",
      "...318 tweets downloaded so far\n",
      "WoodfordHealth  County is done----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for county in counties:\n",
    "    #initialize a list to hold all the tweepy Tweets\n",
    "    alltweets = []\n",
    "\n",
    "    new_tweets = api.user_timeline(screen_name = county,count=200, parser=tweepy.parsers.JSONParser(), tweet_mode = \"extended\")\n",
    "\n",
    "    #save most recent tweets\n",
    "    alltweets.extend(new_tweets)\n",
    "    \n",
    "    \n",
    "    oldest = alltweets[-1]['id'] - 1\n",
    "    \n",
    "    #keep grabbing tweets until there are no tweets left to grab\n",
    "    while len(new_tweets) > 0:\n",
    "\n",
    "        \n",
    "        #print(\"getting tweets before %s\" % (oldest))\n",
    "        #all subsiquent requests use the max_id param to prevent duplicates\n",
    "        new_tweets = api.user_timeline(screen_name = county,count=200,max_id=oldest, parser=tweepy.parsers.JSONParser(), \n",
    "                                       tweet_mode = \"extended\")\n",
    "\n",
    "        #save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "\n",
    "         #update the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1]['id'] - 1\n",
    "\n",
    "        print(\"...%s tweets downloaded so far\" % (len(alltweets)))\n",
    "\n",
    "        #transform the tweepy tweets into a 2D array that will populate the csv\t\n",
    "        outtweets = [[tweet['id_str'], getDate(tweet), tweet['full_text'], getTweetType(tweet['full_text']), \n",
    "                      tweet['user']['screen_name'], tweet['user']['location'],  \n",
    "                      tweet['user']['followers_count'], tweet['user']['friends_count'], tweet['user']['favourites_count'], \n",
    "                      tweet['user']['statuses_count'], tweet['retweet_count'], tweet['favorite_count'], \n",
    "                      tweet['favorited'], getHashtags(tweet), getTweetSource(tweet['source']), getMedia(tweet),\n",
    "                      getTweetURL(tweet)] for tweet in alltweets]\n",
    "\n",
    "        #write the csv\n",
    "        with open('%s_tweets.csv' % county, 'w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"id\",\"created_at\",\"tweet\", \"Tweet_Type\", \"twitter_handle\", \"location\",\"followers\", \n",
    "                             \"following\", \"profile_likes\", \"total_tweets\", \"retweets\", \"favorites\", \"is_favorited\",\n",
    "                             \"Hashtags\", \"source\", \"is_media\", \"Tweet_URL\"])\n",
    "            writer.writerows(outtweets)\n",
    "    print(county,\" County is done----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining all csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = glob.glob('*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(csvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all files in the list\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in csvs])\n",
    "#export to csv\n",
    "combined_csv.to_csv( \"ALLTWEETS.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling all rows and assigning tweets to each group member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('ALLTWEETS.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backing up the original data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling the data frame rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_n=df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We need to consider only tweets by hospitals and not retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n=df_n[df_n['Tweet_Type']=='Tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning top 800 rows to 8 members (100 per member)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n['Team_Member']='Default'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df_n['Team_Member'][0:100]='Devansh'\n",
    "df_n['Team_Member'][101:200]='Adithi'\n",
    "df_n['Team_Member'][201:300]='Shweta'\n",
    "df_n['Team_Member'][301:400]='Anuj'\n",
    "\n",
    "df_n['Team_Member'][401:500]='Kalyani'\n",
    "df_n['Team_Member'][501:600]='Sanjana'\n",
    "df_n['Team_Member'][601:700]='Neil'\n",
    "df_n['Team_Member'][701:800]='Nupur'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save as data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n.to_csv(\"ALL_TWEETS_V2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
